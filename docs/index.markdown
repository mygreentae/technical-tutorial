---
layout: default
title: About
nav_order: 1
permalink: /
---
# CoquiTTS VITS model in Marndarin Chinese
## What does TTS mean?
Text-to-speech (also known as TTS) synthesize speech from a given text input. The most notable TTS systems include Apple's Siri and Amazon's Alexa. 
This tutorial will be a guide to creating our own Chinese TTS model using CoquiTTS's recipe and pre-trained VITS model.
## What is CoquiTTS?
[CoquiTTS](https://github.com/coqui-ai/TTS) is a text-to-speech deep learning toolkit, both used in research and for production. This toolkit offers many "recipes" and pretrained models for a great slection of models. Some of these models include, Tacotron, GlowTTS, and VITS. All of these models will handle different langauges better than others. 
### Recipes and Pre-Trained Models
One of the best features of CoquiTTS is that it allows beginners to learn how to eaily train their own TTS models with the provided pretrained models and the tools for evaluating their models. These tools include recipes. As explained above CoquiTTS supports various pre-trained mdoels with written recipes that the user can modify for their specific project. This makes learning about TTS models or machine learning much easier.

For this tutorial specifically, we are going to create and train a Chinese TTS model using CoquiTTS's VITS model recipe.
## The VITS Recipe
[VITS](https://arxiv.org/pdf/2106.06103.pdf) ( also known as Conditional Variational Autoencoder with Adversarial Learning for End-toEnd Text-to-Speech) is a mixture of a GlowTTS model and a HiFiGAN vocoder. With the architecture of GlowTTS and the HiFiGAN vocoder, audio synthesized by VITS turns out to be more natural sounding with the appropriate parameters and datasets. I know that this is a ton of technical speak, so lets break it down.
### GlowTTS
[GlowTTS](https://arxiv.org/abs/2005.11129) is another TTS model that CoquiTTS also supports. This model isn't autoregressive and uses a flow-based dynamic programming to seach for the most probable alignment between text and speech. The model also generates mel-spectrograms more efficiently than an autoregressive TTS system like Tacotron2. Autoregressive models are statistical models that predict future values based on past values. In contrast to a non-autoregressive model, the sequence generates in parallel to speed up and make the generation process more efficient.

This means that non-autoregressive models can synthesize speech with various intonations and patters and to be able to imitate different pitches of speech which makes a really good choice to implement a Chinese TTS model. However, the reason why we aren't using GlowTTS for this tutorial is because of the addition of HiFiGAN vocoder.
### HiFiGAN vocoder
A vocoder is what turns an intermediate form of audio (or acoustic features) into an audio waveform. Typically, it is used to generate speech from a spectrogram. The [HiFiGAN](https://arxiv.org/abs/2010.05646) vocoder is a GAN (a generative adversarial natwork), the GAN is a network that produces composes of two diffeent models known as the *discriminator* and the "generator*. The generator creates "fake" data that is used to train the dicriminator to distinguish the fake data and the real data. In the TTS sense, GANs are used to create noise in the audio, so we have "more" data to train on. As an adversarial model, the discriminator distinguishes between the output generated by the decoder. Specifically, the HiFiGAN is a GAN based model that is capable of creating high fidelity speech which is almost indistinguishable from the real data. 

